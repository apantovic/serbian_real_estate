{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from contextlib import suppress\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subscrape_data(url, driver):\n",
    "    # 12 - posted_by \n",
    "    # 13 - object_type \n",
    "    # 14 - condition \n",
    "    # 15 - heating \n",
    "    # 16 - floor \n",
    "    # 17 - max_floors\n",
    "\n",
    "    # 19 - flag_available_immediately \n",
    "    # 20 - flag_legal \n",
    "    # 21 - flag_not_last_floor \n",
    "    # 22 - flag_not_in_house\n",
    "    # 23 - flag_VAT_return\n",
    "    # 25 - flag_duplex\n",
    "    # 29 - flag_energy_saving\n",
    "    # 31 - flag_balcony\n",
    "    # 33 - flag_covered_balcony\n",
    "    # 34 - flag_air_condition\n",
    "    # 35 - flag_elevator\n",
    "    # 36 - flag_has_basement\n",
    "    # 38 - flag_telephone\n",
    "    # 39 - flag_cable_tv\n",
    "    # 40 - flag_internet\n",
    "    # 41 - flag_interphone\n",
    "    # 42 - flag_surveliance\n",
    "    # 44 - flag_garage\n",
    "    # 45 - flag_parking\n",
    "    \n",
    "\n",
    "    driver.get(url)\n",
    "    time.sleep(1)      # wait page to load, to grab raw values\n",
    "    page=driver.page_source\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    \n",
    "    try:    \n",
    "        data['Posted_By'] = soup.find('span',attrs={'id':'plh12'}).text\n",
    "    except:\n",
    "        data['Posted_By'] = ''\n",
    "    try:    \n",
    "        data['Object_Type'] = soup.find('span',attrs={'id':'plh13'}).text\n",
    "    except:\n",
    "        data['Object_Type'] = ''\n",
    "    try:    \n",
    "        data['Condition'] = soup.find('span',attrs={'id':'plh14'}).text\n",
    "    except:\n",
    "        data['Condition'] = ''\n",
    "    try:    \n",
    "        data['Heating'] = soup.find('span',attrs={'id':'plh15'}).text\n",
    "    except:\n",
    "        data['Heating'] = ''\n",
    "    try:    \n",
    "        data['Floor'] = str(soup.find('span',attrs={'id':'plh16'}).text)\n",
    "    except:\n",
    "        data['Floor'] = '-1'\n",
    "    try:    \n",
    "        data['Max_Floors'] = str(soup.find('span',attrs={'id':'plh17'}).text)\n",
    "    except:\n",
    "        data['Max_Floors'] = '-1'\n",
    "    \n",
    "        \n",
    "    # flags part\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh19'}).text\n",
    "        data['Flag_Available_Immediately'] = 1\n",
    "    except:\n",
    "        data['Flag_Available_Immediately'] = -1\n",
    "    \n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh20'}).text\n",
    "        data['Flag_Legal'] = 1\n",
    "    except:\n",
    "        data['Flag_Legal'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh21'}).text\n",
    "        data['Flag_Not_Last_Floor'] = 1\n",
    "    except:\n",
    "        data['Flag_Not_Last_Floor'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh22'}).text\n",
    "        data['Flag_Not_Part_of_House'] = 1\n",
    "    except:\n",
    "        data['Flag_Not_Part_of_House'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh23'}).text\n",
    "        data['Flag_VAT_return'] = 1\n",
    "    except:\n",
    "        data['Flag_VAT_return'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh24'}).text\n",
    "        data['Flag_24'] = 1\n",
    "    except:\n",
    "        data['Flag_24'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh25'}).text\n",
    "        data['Flag_Duplex'] = 1\n",
    "    except:\n",
    "        data['Flag_Duplex'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh26'}).text\n",
    "        data['Flag_26'] = 1\n",
    "    except:\n",
    "        data['Flag_26'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh27'}).text\n",
    "        data['Flag_27'] = 1\n",
    "    except:\n",
    "        data['Flag_27'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh28'}).text\n",
    "        data['Flag_28'] = 1\n",
    "    except:\n",
    "        data['Flag_28'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh29'}).text\n",
    "        data['Flag_Energy_Saving'] = 1\n",
    "    except:\n",
    "        data['Flag_Energy_Saving'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh30'}).text\n",
    "        data['Flag_30'] = 1\n",
    "    except:\n",
    "        data['Flag_30'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh31'}).text\n",
    "        data['Flag_Balcony'] = 1\n",
    "    except:\n",
    "        data['Flag_Balcony'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh32'}).text\n",
    "        data['Flag_32'] = 1\n",
    "    except:\n",
    "        data['Flag_32'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh33'}).text\n",
    "        data['Flag_Covered_Balcony'] = 1\n",
    "    except:\n",
    "        data['Flag_Covered_Balcony'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh34'}).text\n",
    "        data['Flag_AirConditioning'] = 1\n",
    "    except:\n",
    "        data['Flag_AirConditioning'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh35'}).text\n",
    "        data['Flag_Elevator'] = 1\n",
    "    except:\n",
    "        data['Flag_Elevator'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh36'}).text\n",
    "        data['Flag_Has_Basement'] = 1\n",
    "    except:\n",
    "        data['Flag_Has_Basement'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh37'}).text\n",
    "        data['Flag_37'] = 1\n",
    "    except:\n",
    "        data['Flag_37'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh38'}).text\n",
    "        data['Flag_Telephone'] = 1\n",
    "    except:\n",
    "        data['Flag_Telephone'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh39'}).text\n",
    "        data['Flag_CableTV'] = 1\n",
    "    except:\n",
    "        data['Flag_CableTV'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh40'}).text\n",
    "        data['Flag_Internet'] = 1\n",
    "    except:\n",
    "        data['Flag_Internet'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh41'}).text\n",
    "        data['Flag_Interphone'] = 1\n",
    "    except:\n",
    "        data['Flag_Interphone'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh42'}).text\n",
    "        data['Flag_Surveliance'] = 1\n",
    "    except:\n",
    "        data['Flag_Surveliance'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh43'}).text\n",
    "        data['Flag_43'] = 1\n",
    "    except:\n",
    "        data['Flag_43'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh44'}).text\n",
    "        data['Flag_Garage'] = 1\n",
    "    except:\n",
    "        data['Flag_Garage'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh45'}).text\n",
    "        data['Flag_Parking'] = 1\n",
    "    except:\n",
    "        data['Flag_Parking'] = -1\n",
    "    try:    \n",
    "        data['Number_of_Busses'] = len(soup.findAll('div',attrs={'class':'city-lines'})[0].findAll('li',attrs={'class':'busses'}))\n",
    "        data['Number_of_Trams'] = len(soup.findAll('div',attrs={'class':'city-lines'})[0].findAll('li',attrs={'class':'trams'}))\n",
    "        data['Number_of_Trolleys'] = len(soup.findAll('div',attrs={'class':'city-lines'})[0].findAll('li',attrs={'class':'trolleybus'})) \n",
    "    except:\n",
    "        data['Number_of_Busses'] = -1\n",
    "        data['Number_of_Trams'] = -1\n",
    "        data['Number_of_Trolleys'] = -1\n",
    "    df = pd.DataFrame(data, index=[0])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_data(base_url, search_addon, page, ad_type,driver):\n",
    "    \n",
    "    additional_facts = pd.DataFrame(columns =['Posted_By', 'Object_Type', 'Condition', 'Heating', 'Floor', 'Max_Floors', 'Flag_Available_Immediately', 'Flag_Legal','Flag_Not_Last_Floor', 'Flag_Not_Part_of_House', 'Flag_VAT_return','Flag_24', 'Flag_Duplex', 'Flag_26', 'Flag_27', 'Flag_28','Flag_Energy_Saving', 'Flag_30', 'Flag_Balcony', 'Flag_32','Flag_Covered_Balcony', 'Flag_AirConditioning', 'Flag_Elevator','Flag_Has_Basement', 'Flag_37', 'Flag_Telephone', 'Flag_CableTV','Flag_Internet', 'Flag_Interphone', 'Flag_Surveliance', 'Flag_43','Flag_Garage', 'Flag_Parking', 'Number_of_Busses', 'Number_of_Trams','Number_of_Trolleys'])\n",
    "\n",
    "    url = base_url+search_addon+str(page)\n",
    "    raw_page = urlopen(url).read()\n",
    "    urlopen(url).close()\n",
    "    bs_page = BeautifulSoup(raw_page, 'html.parser')\n",
    "    \n",
    "    divs = bs_page.findAll('div',{'class','product-item product-list-item {} real-estates my-ad-placeholder'.format(ad_type)})\n",
    "    # initialize empty lists\n",
    "    publish_date, prices, currency, city, city_area, city_subarea, city_street, property_type, property_size, property_norooms, desc, link_to_property   = ([] for _ in range(12))\n",
    "\n",
    "    if divs: # if list is not empty - to speed things up for empty segments\n",
    "        for div in divs:\n",
    "\n",
    "            publish_date.append(div.findAll('div',{'class','pi-img-wrapper-under'})[0].span.text)       # extract date of ad posting\n",
    "\n",
    "            price = div.findAll('div',{'data-value','central-feature'})[0].span.text                    # price and currency info\n",
    "            price = price.split('\\xa0')\n",
    "\n",
    "            prices.append(int(price[0].translate(str.maketrans({'.': '', ',': ''}))))\n",
    "            currency.append(price[1])\n",
    "\n",
    "            city_info = div.findAll('div',{'class','col-md-6 col-sm-5 col-xs-6 col-lg-6 sm-margin'})[0] # extract city, area and street\n",
    "\n",
    "            city.append(city_info.find('ul',attrs={'class':'subtitle-places'}).text.split('\\xa0')[0])\n",
    "            city_area.append(city_info.find('ul',attrs={'class':'subtitle-places'}).text.split('\\xa0')[1])\n",
    "            city_subarea.append(city_info.find('ul',attrs={'class':'subtitle-places'}).text.split('\\xa0')[2])\n",
    "            city_street.append(city_info.find('ul',attrs={'class':'subtitle-places'}).text.split('\\xa0')[3])\n",
    "\n",
    "            features = div.find('ul',attrs={'class':'ad-features'})                                     # extract price, size and type of posting\n",
    "\n",
    "            property_type.append(features.findAll('li',{'class':'col-p-1-3'})[0].div.text.split('\\xa0')[0])\n",
    "            property_size.append(features.findAll('li',{'class':'col-p-1-3'})[1].div.text.split('\\xa0')[0])\n",
    "            property_norooms.append(features.findAll('li',{'class':'col-p-1-3'})[2].div.text.split('\\xa0')[0])\n",
    "\n",
    "            try: \n",
    "                desc.append(div.findAll('p',{'class':'text-description-list ad-description short-desc'})[0].text)\n",
    "            except:\n",
    "                desc.append('')\n",
    "            link_to_property.append(div.find('h3').a['href'])\n",
    "    #        print(link_to_property[len(link_to_property)-1])\n",
    "            tmp_additional_facts = subscrape_data(str(base_url+link_to_property[len(link_to_property)-1]),driver)\n",
    "\n",
    "            additional_facts = additional_facts.append(tmp_additional_facts, ignore_index=True)\n",
    "\n",
    "        df = pd.DataFrame(list(zip(publish_date,prices,currency,city,city_area,city_subarea,city_street,property_type,property_size,property_norooms,desc, link_to_property)), \n",
    "               columns =['Publish_Date', 'Price','Currency','City','City_Area','City_Subarea','Street','Property_Type','Property_Size_sqmtr','No_of_Rooms','Desc','Link_to_Property'])\n",
    "        df['Ad_Type'] = ad_type\n",
    "    else:\n",
    "        df = pd.DataFrame(list(zip(publish_date,prices,currency,city,city_area,city_subarea,city_street,property_type,property_size,property_norooms,desc, link_to_property)), \n",
    "               columns =['Publish_Date', 'Price','Currency','City','City_Area','City_Subarea','Street','Property_Type','Property_Size_sqmtr','No_of_Rooms','Desc','Link_to_Property'])\n",
    "        df['Ad_Type'] = None\n",
    "\n",
    "    return pd.concat([df, additional_facts], axis=1,sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page: 654\n",
      "20\n",
      "page: 655\n",
      "20\n",
      "page: 656\n",
      "20\n",
      "page: 657\n",
      "19\n",
      "page: 658\n",
      "18\n",
      "page: 659\n",
      "20\n",
      "page: 660\n",
      "20\n",
      "page: 661\n",
      "19\n",
      "page: 662\n",
      "18\n",
      "page: 663\n",
      "20\n",
      "page: 664\n",
      "20\n",
      "page: 665\n",
      "18\n",
      "page: 666\n",
      "20\n",
      "page: 667\n",
      "18\n",
      "page: 668\n",
      "20\n",
      "page: 669\n",
      "20\n",
      "page: 670\n",
      "20\n",
      "page: 671\n",
      "19\n",
      "page: 672\n",
      "20\n",
      "page: 673\n",
      "20\n",
      "page: 674\n",
      "20\n",
      "page: 675\n",
      "20\n",
      "page: 676\n",
      "20\n",
      "page: 677\n",
      "14\n",
      "page: 678\n",
      "19\n",
      "page: 679\n",
      "19\n",
      "page: 680\n",
      "20\n",
      "page: 681\n",
      "20\n",
      "page: 682\n",
      "20\n",
      "page: 683\n",
      "20\n",
      "page: 684\n",
      "20\n",
      "page: 685\n",
      "20\n",
      "page: 686\n",
      "20\n",
      "page: 687\n",
      "20\n",
      "page: 688\n",
      "20\n",
      "page: 689\n",
      "20\n",
      "page: 690\n",
      "20\n",
      "page: 691\n",
      "20\n",
      "page: 692\n",
      "20\n",
      "page: 693\n",
      "20\n",
      "page: 694\n",
      "20\n",
      "page: 695\n",
      "19\n",
      "page: 696\n",
      "18\n",
      "page: 697\n",
      "20\n",
      "page: 698\n",
      "20\n",
      "page: 699\n",
      "20\n",
      "page: 700\n",
      "20\n",
      "page: 701\n",
      "20\n",
      "page: 702\n",
      "20\n",
      "page: 703\n",
      "20\n",
      "page: 704\n",
      "18\n",
      "page: 705\n",
      "20\n",
      "page: 706\n",
      "19\n",
      "page: 707\n",
      "20\n",
      "page: 708\n",
      "20\n",
      "page: 709\n",
      "20\n",
      "page: 710\n",
      "20\n",
      "page: 711\n",
      "19\n",
      "page: 712\n",
      "19\n",
      "page: 713\n",
      "17\n",
      "page: 714\n",
      "19\n",
      "page: 715\n",
      "18\n",
      "page: 716\n",
      "20\n",
      "page: 717\n",
      "20\n",
      "page: 718\n",
      "19\n",
      "page: 719\n",
      "19\n",
      "page: 720\n",
      "20\n",
      "page: 721\n",
      "20\n",
      "page: 722\n",
      "20\n",
      "page: 723\n",
      "20\n",
      "page: 724\n",
      "20\n",
      "page: 725\n",
      "20\n",
      "page: 726\n",
      "20\n",
      "page: 727\n",
      "18\n",
      "page: 728\n",
      "20\n",
      "page: 729\n",
      "19\n",
      "page: 730\n",
      "20\n",
      "page: 731\n",
      "20\n",
      "page: 732\n",
      "20\n",
      "page: 733\n",
      "20\n",
      "page: 734\n",
      "20\n",
      "page: 735\n",
      "20\n",
      "page: 736\n",
      "20\n",
      "page: 737\n"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "Message: timeout\n  (Session info: chrome=78.0.3904.97)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-893ddc0842e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#     print(len(tmp_df))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#     df = pd.concat([df, tmp_df], axis=0, ignore_index=True,sort=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mtmp_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscrape_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://www.halooglasi.com'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'/nekretnine/prodaja-stanova?page='\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Standard'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmp_df\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-689116e7a8b5>\u001b[0m in \u001b[0;36mscrape_data\u001b[1;34m(base_url, search_addon, page, ad_type, driver)\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mlink_to_property\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'h3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;31m#        print(link_to_property[len(link_to_property)-1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mtmp_additional_facts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubscrape_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlink_to_property\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink_to_property\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0madditional_facts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madditional_facts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_additional_facts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-dd362c9224fa>\u001b[0m in \u001b[0;36msubscrape_data\u001b[1;34m(url, driver)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m      \u001b[1;31m# wait page to load, to grab raw values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mpage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dash\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \"\"\"\n\u001b[1;32m--> 333\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dash\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dash\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: timeout\n  (Session info: chrome=78.0.3904.97)\n"
     ]
    }
   ],
   "source": [
    "num_pages = 1478\n",
    "\n",
    "for page in range(654,num_pages):\n",
    "    driver = Chrome('chromedriver1.exe')\n",
    "    print('page: ' + str(page))\n",
    "#     tmp_df = scrape_data('https://www.halooglasi.com', '/nekretnine/prodaja-stanova?page=', page, 'Premium',driver)\n",
    "#     print(len(tmp_df))\n",
    "#     df = pd.concat([df, tmp_df], axis=0, ignore_index=True,sort=True)\n",
    "#     tmp_df = scrape_data('https://www.halooglasi.com', '/nekretnine/prodaja-stanova?page=', page, 'Top',driver)\n",
    "#     print(len(tmp_df))\n",
    "#     df = pd.concat([df, tmp_df], axis=0, ignore_index=True,sort=True)\n",
    "    tmp_df = scrape_data('https://www.halooglasi.com', '/nekretnine/prodaja-stanova?page=', page, 'Standard',driver)\n",
    "    print(len(tmp_df))\n",
    "    df = pd.concat([df, tmp_df], axis=0, ignore_index=True,sort=True)\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates().to_csv('halooglasi_data_20191106.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('halooglasi_data_20191106.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ad_Type</th>\n",
       "      <th>City</th>\n",
       "      <th>City_Area</th>\n",
       "      <th>City_Subarea</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Currency</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Flag_24</th>\n",
       "      <th>Flag_26</th>\n",
       "      <th>Flag_27</th>\n",
       "      <th>...</th>\n",
       "      <th>Number_of_Busses</th>\n",
       "      <th>Number_of_Trams</th>\n",
       "      <th>Number_of_Trolleys</th>\n",
       "      <th>Object_Type</th>\n",
       "      <th>Posted_By</th>\n",
       "      <th>Price</th>\n",
       "      <th>Property_Size_sqmtr</th>\n",
       "      <th>Property_Type</th>\n",
       "      <th>Publish_Date</th>\n",
       "      <th>Street</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Beograd</td>\n",
       "      <td>Opština Vračar</td>\n",
       "      <td>Krunska</td>\n",
       "      <td>Lux</td>\n",
       "      <td>€</td>\n",
       "      <td>AGENCIJSKA PROVIZIJA 2% OPIS NEKRETNINE: Uknji...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Agencija</td>\n",
       "      <td>300000</td>\n",
       "      <td>108</td>\n",
       "      <td>Stan</td>\n",
       "      <td>06.11.2019</td>\n",
       "      <td>Kneginje Zorke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Beograd</td>\n",
       "      <td>Opština Zvezdara</td>\n",
       "      <td>Kluz</td>\n",
       "      <td>Izvorno stanje</td>\n",
       "      <td>€</td>\n",
       "      <td>Dvoiposoban stan neto površine 65,00 m2 po cen...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Novogradnja</td>\n",
       "      <td>Investitor</td>\n",
       "      <td>103409</td>\n",
       "      <td>65</td>\n",
       "      <td>Stan</td>\n",
       "      <td>06.11.2019</td>\n",
       "      <td>Živka Davidovića 81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Beograd</td>\n",
       "      <td>Opština Vračar</td>\n",
       "      <td>Hram svetog Save</td>\n",
       "      <td>NaN</td>\n",
       "      <td>€</td>\n",
       "      <td>HITNA PRODAJA! Hram, Patrijarha Varnave, 4.0, ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Novogradnja</td>\n",
       "      <td>Agencija</td>\n",
       "      <td>400000</td>\n",
       "      <td>185</td>\n",
       "      <td>Stan</td>\n",
       "      <td>06.11.2019</td>\n",
       "      <td>Patrijarha Varnave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Beograd</td>\n",
       "      <td>Opština Savski venac</td>\n",
       "      <td>Beograd na vodi</td>\n",
       "      <td>Lux</td>\n",
       "      <td>€</td>\n",
       "      <td>Ekskluzivan, DELUXE stan, BEOGRAD NA VODI - zg...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Novogradnja</td>\n",
       "      <td>Agencija</td>\n",
       "      <td>270000</td>\n",
       "      <td>80</td>\n",
       "      <td>Stan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Beograd</td>\n",
       "      <td>Opština Zemun</td>\n",
       "      <td>Donji grad</td>\n",
       "      <td>Izvorno stanje</td>\n",
       "      <td>€</td>\n",
       "      <td>Stan se nalazi u lameli 8 u IV fazi izgradnje ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Novogradnja</td>\n",
       "      <td>Investitor</td>\n",
       "      <td>267600</td>\n",
       "      <td>127,44</td>\n",
       "      <td>Stan</td>\n",
       "      <td>06.11.2019</td>\n",
       "      <td>Petra Kočića</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ad_Type     City             City_Area      City_Subarea       Condition  \\\n",
       "0  Premium  Beograd        Opština Vračar           Krunska             Lux   \n",
       "1  Premium  Beograd      Opština Zvezdara              Kluz  Izvorno stanje   \n",
       "2  Premium  Beograd        Opština Vračar  Hram svetog Save             NaN   \n",
       "3  Premium  Beograd  Opština Savski venac   Beograd na vodi             Lux   \n",
       "4  Premium  Beograd         Opština Zemun        Donji grad  Izvorno stanje   \n",
       "\n",
       "  Currency                                               Desc  Flag_24  \\\n",
       "0        €  AGENCIJSKA PROVIZIJA 2% OPIS NEKRETNINE: Uknji...       -1   \n",
       "1        €  Dvoiposoban stan neto površine 65,00 m2 po cen...       -1   \n",
       "2        €  HITNA PRODAJA! Hram, Patrijarha Varnave, 4.0, ...       -1   \n",
       "3        €  Ekskluzivan, DELUXE stan, BEOGRAD NA VODI - zg...       -1   \n",
       "4        €  Stan se nalazi u lameli 8 u IV fazi izgradnje ...       -1   \n",
       "\n",
       "   Flag_26  Flag_27  ...  Number_of_Busses  Number_of_Trams  \\\n",
       "0       -1       -1  ...                 3                0   \n",
       "1        1       -1  ...                 0                0   \n",
       "2       -1       -1  ...                 0                0   \n",
       "3       -1       -1  ...                 0                0   \n",
       "4       -1       -1  ...                 0                0   \n",
       "\n",
       "   Number_of_Trolleys  Object_Type   Posted_By   Price  Property_Size_sqmtr  \\\n",
       "0                   4          NaN    Agencija  300000                  108   \n",
       "1                   0  Novogradnja  Investitor  103409                   65   \n",
       "2                   0  Novogradnja    Agencija  400000                  185   \n",
       "3                   0  Novogradnja    Agencija  270000                   80   \n",
       "4                   0  Novogradnja  Investitor  267600               127,44   \n",
       "\n",
       "   Property_Type  Publish_Date               Street  \n",
       "0           Stan    06.11.2019       Kneginje Zorke  \n",
       "1           Stan    06.11.2019  Živka Davidovića 81  \n",
       "2           Stan    06.11.2019   Patrijarha Varnave  \n",
       "3           Stan           NaN                Vista  \n",
       "4           Stan    06.11.2019         Petra Kočića  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.halooglasi.com/nekretnine/prodaja-stanova/zelena-avenija-zemun-novogradnja-pametne-zgra/5425634578403?kid=4&sid=1573042134158'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "posted_by, object_type, condition, heating, floor, max_floors, flag_legal, flag_available_immediately, flag_not_last_floor,flag_balcony, flag_elevator, flag_internet, flag_surveliance, flag_air_condition, flag_cable_tv, flag_garage, flag_interphone, number_of_busses, number_of_trams, number_of_trolleys = ([] for _ in range(20))\n",
    "driver = Chrome('chromedriver1.exe')\n",
    "\n",
    "driver.get(url)\n",
    "time.sleep(1)      # wait page to load, to grab raw values\n",
    "page=driver.page_source\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "info = soup.findAll('div',attrs={'class':'col-lg-7 col-md-7 datasheet-features-type'})\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = Chrome('chromedriver1.exe')\n",
    "url = 'https://www.halooglasi.com/nekretnine/prodaja-stanova/zelena-avenija-zemun-novogradnja-pametne-zgra/5425634578403?kid=4&sid=1573042134158'\n",
    "a = subscrape_data(url, driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ad_Type</th>\n",
       "      <th>City</th>\n",
       "      <th>City_Area</th>\n",
       "      <th>City_Subarea</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Currency</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Flag_Air_Condition</th>\n",
       "      <th>Flag_Available_Immediately</th>\n",
       "      <th>Flag_Balcony</th>\n",
       "      <th>...</th>\n",
       "      <th>Num_of_Busses</th>\n",
       "      <th>Num_of_Trams</th>\n",
       "      <th>Num_of_Trolleys</th>\n",
       "      <th>Object_Type</th>\n",
       "      <th>Posted_By</th>\n",
       "      <th>Price</th>\n",
       "      <th>Property_Size_sqmtr</th>\n",
       "      <th>Property_Type</th>\n",
       "      <th>Publish_Date</th>\n",
       "      <th>Street</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Beograd</td>\n",
       "      <td>Opština Zvezdara</td>\n",
       "      <td>Mali Mokri Lug</td>\n",
       "      <td>Izvorno stanje</td>\n",
       "      <td>€</td>\n",
       "      <td>Stambeni objekat se nalazi u Partizanskoj ulic...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Novogradnja</td>\n",
       "      <td>Investitor</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>36,39</td>\n",
       "      <td>Stan</td>\n",
       "      <td>02.11.2019</td>\n",
       "      <td>Partizanska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Beograd</td>\n",
       "      <td>Opština Zvezdara</td>\n",
       "      <td>Mali Mokri Lug</td>\n",
       "      <td>Izvorno stanje</td>\n",
       "      <td>€</td>\n",
       "      <td>Stambeni objekat se nalazi u Partizanskoj ulic...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Novogradnja</td>\n",
       "      <td>Investitor</td>\n",
       "      <td>50150.0</td>\n",
       "      <td>40,15</td>\n",
       "      <td>Stan</td>\n",
       "      <td>02.11.2019</td>\n",
       "      <td>Partizanska</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ad_Type     City         City_Area    City_Subarea       Condition  \\\n",
       "1  Premium  Beograd  Opština Zvezdara  Mali Mokri Lug  Izvorno stanje   \n",
       "2  Premium  Beograd  Opština Zvezdara  Mali Mokri Lug  Izvorno stanje   \n",
       "\n",
       "  Currency                                               Desc  \\\n",
       "1        €  Stambeni objekat se nalazi u Partizanskoj ulic...   \n",
       "2        €  Stambeni objekat se nalazi u Partizanskoj ulic...   \n",
       "\n",
       "   Flag_Air_Condition  Flag_Available_Immediately  Flag_Balcony  ...  \\\n",
       "1                   1                           1             1  ...   \n",
       "2                   1                           1             1  ...   \n",
       "\n",
       "   Num_of_Busses  Num_of_Trams  Num_of_Trolleys  Object_Type   Posted_By  \\\n",
       "1              9             0                0  Novogradnja  Investitor   \n",
       "2              9             0                0  Novogradnja  Investitor   \n",
       "\n",
       "     Price  Property_Size_sqmtr  Property_Type  Publish_Date       Street  \n",
       "1  45000.0                36,39           Stan    02.11.2019  Partizanska  \n",
       "2  50150.0                40,15           Stan    02.11.2019  Partizanska  \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subscrape_data(url, driver):\n",
    "    # 12 - posted_by \n",
    "    # 13 - object_type \n",
    "    # 14 - condition \n",
    "    # 15 - heating \n",
    "    # 16 - floor \n",
    "    # 17 - max_floors\n",
    "\n",
    "    # 19 - flag_available_immediately \n",
    "    # 20 - flag_legal \n",
    "    # 21 - flag_not_last_floor \n",
    "    # 22 - flag_not_in_house\n",
    "    # 23 - flag_VAT_return\n",
    "    # 25 - flag_duplex\n",
    "    # 29 - flag_energy_saving\n",
    "    # 31 - flag_balcony\n",
    "    # 33 - flag_covered_balcony\n",
    "    # 34 - flag_air_condition\n",
    "    # 35 - flag_elevator\n",
    "    # 36 - flag_has_basement\n",
    "    # 38 - flag_telephone\n",
    "    # 39 - flag_cable_tv\n",
    "    # 40 - flag_internet\n",
    "    # 41 - flag_interphone\n",
    "    # 42 - flag_surveliance\n",
    "    # 44 - flag_garage\n",
    "    # 45 - flag_parking\n",
    "    \n",
    "\n",
    "    driver.get(url)\n",
    "    time.sleep(1)      # wait page to load, to grab raw values\n",
    "    page=driver.page_source\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    \n",
    "    try:    \n",
    "        data['Posted_By'] = soup.find('span',attrs={'id':'plh12'}).text\n",
    "    except:\n",
    "        data['Posted_By'] = ''\n",
    "    try:    \n",
    "        data['Object_Type'] = soup.find('span',attrs={'id':'plh13'}).text\n",
    "    except:\n",
    "        data['Object_Type'] = ''\n",
    "    try:    \n",
    "        data['Condition'] = soup.find('span',attrs={'id':'plh14'}).text\n",
    "    except:\n",
    "        data['Condition'] = ''\n",
    "    try:    \n",
    "        data['Heating'] = soup.find('span',attrs={'id':'plh15'}).text\n",
    "    except:\n",
    "        data['Heating'] = ''\n",
    "    try:    \n",
    "        data['Floor'] = str(soup.find('span',attrs={'id':'plh16'}).text)\n",
    "    except:\n",
    "        data['Floor'] = '-1'\n",
    "    try:    \n",
    "        data['Max_Floors'] = str(soup.find('span',attrs={'id':'plh17'}).text)\n",
    "    except:\n",
    "        data['Max_Floors'] = '-1'\n",
    "    \n",
    "        \n",
    "    # flags part\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh19'}).text\n",
    "        data['Flag_Available_Immediately'] = 1\n",
    "    except:\n",
    "        data['Flag_Available_Immediately'] = -1\n",
    "    \n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh20'}).text\n",
    "        data['Flag_Legal'] = 1\n",
    "    except:\n",
    "        data['Flag_Legal'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh21'}).text\n",
    "        data['Flag_Not_Last_Floor'] = 1\n",
    "    except:\n",
    "        data['Flag_Not_Last_Floor'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh22'}).text\n",
    "        data['Flag_Not_Part_of_House'] = 1\n",
    "    except:\n",
    "        data['Flag_Not_Part_of_House'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh23'}).text\n",
    "        data['Flag_VAT_return'] = 1\n",
    "    except:\n",
    "        data['Flag_VAT_return'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh24'}).text\n",
    "        data['Flag_24'] = 1\n",
    "    except:\n",
    "        data['Flag_24'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh25'}).text\n",
    "        data['Flag_Duplex'] = 1\n",
    "    except:\n",
    "        data['Flag_Duplex'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh26'}).text\n",
    "        data['Flag_26'] = 1\n",
    "    except:\n",
    "        data['Flag_26'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh27'}).text\n",
    "        data['Flag_27'] = 1\n",
    "    except:\n",
    "        data['Flag_27'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh28'}).text\n",
    "        data['Flag_28'] = 1\n",
    "    except:\n",
    "        data['Flag_28'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh29'}).text\n",
    "        data['Flag_Energy_Saving'] = 1\n",
    "    except:\n",
    "        data['Flag_Energy_Saving'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh30'}).text\n",
    "        data['Flag_30'] = 1\n",
    "    except:\n",
    "        data['Flag_30'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh31'}).text\n",
    "        data['Flag_Balcony'] = 1\n",
    "    except:\n",
    "        data['Flag_Balcony'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh32'}).text\n",
    "        data['Flag_32'] = 1\n",
    "    except:\n",
    "        data['Flag_32'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh33'}).text\n",
    "        data['Flag_Covered_Balcony'] = 1\n",
    "    except:\n",
    "        data['Flag_Covered_Balcony'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh34'}).text\n",
    "        data['Flag_AirConditioning'] = 1\n",
    "    except:\n",
    "        data['Flag_AirConditioning'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh35'}).text\n",
    "        data['Flag_Elevator'] = 1\n",
    "    except:\n",
    "        data['Flag_Elevator'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh36'}).text\n",
    "        data['Flag_Has_Basement'] = 1\n",
    "    except:\n",
    "        data['Flag_Has_Basement'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh37'}).text\n",
    "        data['Flag_37'] = 1\n",
    "    except:\n",
    "        data['Flag_37'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh38'}).text\n",
    "        data['Flag_Telephone'] = 1\n",
    "    except:\n",
    "        data['Flag_Telephone'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh39'}).text\n",
    "        data['Flag_CableTV'] = 1\n",
    "    except:\n",
    "        data['Flag_CableTV'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh40'}).text\n",
    "        data['Flag_Internet'] = 1\n",
    "    except:\n",
    "        data['Flag_Internet'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh41'}).text\n",
    "        data['Flag_Interphone'] = 1\n",
    "    except:\n",
    "        data['Flag_Interphone'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh42'}).text\n",
    "        data['Flag_Surveliance'] = 1\n",
    "    except:\n",
    "        data['Flag_Surveliance'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh43'}).text\n",
    "        data['Flag_43'] = 1\n",
    "    except:\n",
    "        data['Flag_43'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh44'}).text\n",
    "        data['Flag_Garage'] = 1\n",
    "    except:\n",
    "        data['Flag_Garage'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh45'}).text\n",
    "        data['Flag_Parking'] = 1\n",
    "    except:\n",
    "        data['Flag_Parking'] = -1\n",
    "    try:    \n",
    "        data['Number_of_Busses'] = len(soup.findAll('div',attrs={'class':'city-lines'})[0].findAll('li',attrs={'class':'busses'}))\n",
    "        data['Number_of_Trams'] = len(soup.findAll('div',attrs={'class':'city-lines'})[0].findAll('li',attrs={'class':'trams'}))\n",
    "        data['Number_of_Trolleys'] = len(soup.findAll('div',attrs={'class':'city-lines'})[0].findAll('li',attrs={'class':'trolleybus'})) \n",
    "    except:\n",
    "        data['Number_of_Busses'] = -1\n",
    "        data['Number_of_Trams'] = -1\n",
    "        data['Number_of_Trolleys'] = -1\n",
    "    df = pd.DataFrame(data, index=[0])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
