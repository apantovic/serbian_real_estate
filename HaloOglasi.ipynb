{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from contextlib import suppress\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subscrape_data(url, driver):\n",
    "    # 12 - posted_by \n",
    "    # 13 - object_type \n",
    "    # 14 - condition \n",
    "    # 15 - heating \n",
    "    # 16 - floor \n",
    "    # 17 - max_floors\n",
    "\n",
    "    # 19 - flag_available_immediately \n",
    "    # 20 - flag_legal \n",
    "    # 21 - flag_not_last_floor \n",
    "    # 22 - flag_not_in_house\n",
    "    # 23 - flag_VAT_return\n",
    "    # 25 - flag_duplex\n",
    "    # 29 - flag_energy_saving\n",
    "    # 31 - flag_balcony\n",
    "    # 33 - flag_covered_balcony\n",
    "    # 34 - flag_air_condition\n",
    "    # 35 - flag_elevator\n",
    "    # 36 - flag_has_basement\n",
    "    # 38 - flag_telephone\n",
    "    # 39 - flag_cable_tv\n",
    "    # 40 - flag_internet\n",
    "    # 41 - flag_interphone\n",
    "    # 42 - flag_surveliance\n",
    "    # 44 - flag_garage\n",
    "    # 45 - flag_parking\n",
    "    \n",
    "\n",
    "    driver.get(url)\n",
    "    time.sleep(1)      # wait page to load, to grab raw values\n",
    "    page=driver.page_source\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    \n",
    "    try:    \n",
    "        data['Posted_By'] = soup.find('span',attrs={'id':'plh12'}).text\n",
    "    except:\n",
    "        data['Posted_By'] = ''\n",
    "    try:    \n",
    "        data['Object_Type'] = soup.find('span',attrs={'id':'plh13'}).text\n",
    "    except:\n",
    "        data['Object_Type'] = ''\n",
    "    try:    \n",
    "        data['Condition'] = soup.find('span',attrs={'id':'plh14'}).text\n",
    "    except:\n",
    "        data['Condition'] = ''\n",
    "    try:    \n",
    "        data['Heating'] = soup.find('span',attrs={'id':'plh15'}).text\n",
    "    except:\n",
    "        data['Heating'] = ''\n",
    "    try:    \n",
    "        data['Floor'] = str(soup.find('span',attrs={'id':'plh16'}).text)\n",
    "    except:\n",
    "        data['Floor'] = '-1'\n",
    "    try:    \n",
    "        data['Max_Floors'] = str(soup.find('span',attrs={'id':'plh17'}).text)\n",
    "    except:\n",
    "        data['Max_Floors'] = '-1'\n",
    "    \n",
    "        \n",
    "    # flags part\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh19'}).text\n",
    "        data['Flag_Available_Immediately'] = 1\n",
    "    except:\n",
    "        data['Flag_Available_Immediately'] = -1\n",
    "    \n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh20'}).text\n",
    "        data['Flag_Legal'] = 1\n",
    "    except:\n",
    "        data['Flag_Legal'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh21'}).text\n",
    "        data['Flag_Not_Last_Floor'] = 1\n",
    "    except:\n",
    "        data['Flag_Not_Last_Floor'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh22'}).text\n",
    "        data['Flag_Not_Part_of_House'] = 1\n",
    "    except:\n",
    "        data['Flag_Not_Part_of_House'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh23'}).text\n",
    "        data['Flag_VAT_return'] = 1\n",
    "    except:\n",
    "        data['Flag_VAT_return'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh24'}).text\n",
    "        data['Flag_24'] = 1\n",
    "    except:\n",
    "        data['Flag_24'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh25'}).text\n",
    "        data['Flag_Duplex'] = 1\n",
    "    except:\n",
    "        data['Flag_Duplex'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh26'}).text\n",
    "        data['Flag_26'] = 1\n",
    "    except:\n",
    "        data['Flag_26'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh27'}).text\n",
    "        data['Flag_27'] = 1\n",
    "    except:\n",
    "        data['Flag_27'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh28'}).text\n",
    "        data['Flag_28'] = 1\n",
    "    except:\n",
    "        data['Flag_28'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh29'}).text\n",
    "        data['Flag_Energy_Saving'] = 1\n",
    "    except:\n",
    "        data['Flag_Energy_Saving'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh30'}).text\n",
    "        data['Flag_30'] = 1\n",
    "    except:\n",
    "        data['Flag_30'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh31'}).text\n",
    "        data['Flag_Balcony'] = 1\n",
    "    except:\n",
    "        data['Flag_Balcony'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh32'}).text\n",
    "        data['Flag_32'] = 1\n",
    "    except:\n",
    "        data['Flag_32'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh33'}).text\n",
    "        data['Flag_Covered_Balcony'] = 1\n",
    "    except:\n",
    "        data['Flag_Covered_Balcony'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh34'}).text\n",
    "        data['Flag_AirConditioning'] = 1\n",
    "    except:\n",
    "        data['Flag_AirConditioning'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh35'}).text\n",
    "        data['Flag_Elevator'] = 1\n",
    "    except:\n",
    "        data['Flag_Elevator'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh36'}).text\n",
    "        data['Flag_Has_Basement'] = 1\n",
    "    except:\n",
    "        data['Flag_Has_Basement'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh37'}).text\n",
    "        data['Flag_37'] = 1\n",
    "    except:\n",
    "        data['Flag_37'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh38'}).text\n",
    "        data['Flag_Telephone'] = 1\n",
    "    except:\n",
    "        data['Flag_Telephone'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh39'}).text\n",
    "        data['Flag_CableTV'] = 1\n",
    "    except:\n",
    "        data['Flag_CableTV'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh40'}).text\n",
    "        data['Flag_Internet'] = 1\n",
    "    except:\n",
    "        data['Flag_Internet'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh41'}).text\n",
    "        data['Flag_Interphone'] = 1\n",
    "    except:\n",
    "        data['Flag_Interphone'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh42'}).text\n",
    "        data['Flag_Surveliance'] = 1\n",
    "    except:\n",
    "        data['Flag_Surveliance'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh43'}).text\n",
    "        data['Flag_43'] = 1\n",
    "    except:\n",
    "        data['Flag_43'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh44'}).text\n",
    "        data['Flag_Garage'] = 1\n",
    "    except:\n",
    "        data['Flag_Garage'] = -1\n",
    "    try:\n",
    "        soup.find('span',attrs={'id':'plh45'}).text\n",
    "        data['Flag_Parking'] = 1\n",
    "    except:\n",
    "        data['Flag_Parking'] = -1\n",
    "    try:    \n",
    "        data['Number_of_Busses'] = len(soup.findAll('div',attrs={'class':'city-lines'})[0].findAll('li',attrs={'class':'busses'}))\n",
    "        data['Number_of_Trams'] = len(soup.findAll('div',attrs={'class':'city-lines'})[0].findAll('li',attrs={'class':'trams'}))\n",
    "        data['Number_of_Trolleys'] = len(soup.findAll('div',attrs={'class':'city-lines'})[0].findAll('li',attrs={'class':'trolleybus'})) \n",
    "    except:\n",
    "        data['Number_of_Busses'] = -1\n",
    "        data['Number_of_Trams'] = -1\n",
    "        data['Number_of_Trolleys'] = -1\n",
    "    df = pd.DataFrame(data, index=[0])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_data(base_url, search_addon, page, ad_type,driver):\n",
    "    \n",
    "    additional_facts = pd.DataFrame(columns =['Posted_By', 'Object_Type', 'Condition', 'Heating', 'Floor', 'Max_Floors', 'Flag_Available_Immediately', 'Flag_Legal','Flag_Not_Last_Floor', 'Flag_Not_Part_of_House', 'Flag_VAT_return','Flag_24', 'Flag_Duplex', 'Flag_26', 'Flag_27', 'Flag_28','Flag_Energy_Saving', 'Flag_30', 'Flag_Balcony', 'Flag_32','Flag_Covered_Balcony', 'Flag_AirConditioning', 'Flag_Elevator','Flag_Has_Basement', 'Flag_37', 'Flag_Telephone', 'Flag_CableTV','Flag_Internet', 'Flag_Interphone', 'Flag_Surveliance', 'Flag_43','Flag_Garage', 'Flag_Parking', 'Number_of_Busses', 'Number_of_Trams','Number_of_Trolleys'])\n",
    "\n",
    "    url = base_url+search_addon+str(page)\n",
    "    raw_page = urlopen(url).read()\n",
    "    urlopen(url).close()\n",
    "    bs_page = BeautifulSoup(raw_page, 'html.parser')\n",
    "    \n",
    "    divs = bs_page.findAll('div',{'class','product-item product-list-item {} real-estates my-ad-placeholder'.format(ad_type)})\n",
    "    # initialize empty lists\n",
    "    publish_date, prices, currency, city, city_area, city_subarea, city_street, property_type, property_size, property_norooms, desc, link_to_property   = ([] for _ in range(12))\n",
    "\n",
    "    if divs: # if list is not empty - to speed things up for empty segments\n",
    "        for div in divs:\n",
    "\n",
    "            publish_date.append(div.findAll('div',{'class','pi-img-wrapper-under'})[0].span.text)       # extract date of ad posting\n",
    "\n",
    "            price = div.findAll('div',{'data-value','central-feature'})[0].span.text                    # price and currency info\n",
    "            price = price.split('\\xa0')\n",
    "\n",
    "            prices.append(int(price[0].translate(str.maketrans({'.': '', ',': ''}))))\n",
    "            currency.append(price[1])\n",
    "\n",
    "            city_info = div.findAll('div',{'class','col-md-6 col-sm-5 col-xs-6 col-lg-6 sm-margin'})[0] # extract city, area and street\n",
    "\n",
    "            city.append(city_info.find('ul',attrs={'class':'subtitle-places'}).text.split('\\xa0')[0])\n",
    "            city_area.append(city_info.find('ul',attrs={'class':'subtitle-places'}).text.split('\\xa0')[1])\n",
    "            city_subarea.append(city_info.find('ul',attrs={'class':'subtitle-places'}).text.split('\\xa0')[2])\n",
    "            city_street.append(city_info.find('ul',attrs={'class':'subtitle-places'}).text.split('\\xa0')[3])\n",
    "\n",
    "            features = div.find('ul',attrs={'class':'ad-features'})                                     # extract price, size and type of posting\n",
    "\n",
    "            property_type.append(features.findAll('li',{'class':'col-p-1-3'})[0].div.text.split('\\xa0')[0])\n",
    "            property_size.append(features.findAll('li',{'class':'col-p-1-3'})[1].div.text.split('\\xa0')[0])\n",
    "            property_norooms.append(features.findAll('li',{'class':'col-p-1-3'})[2].div.text.split('\\xa0')[0])\n",
    "\n",
    "            try: \n",
    "                desc.append(div.findAll('p',{'class':'text-description-list ad-description short-desc'})[0].text)\n",
    "            except:\n",
    "                desc.append('')\n",
    "            link_to_property.append(div.find('h3').a['href'])\n",
    "    #        print(link_to_property[len(link_to_property)-1])\n",
    "            tmp_additional_facts = subscrape_data(str(base_url+link_to_property[len(link_to_property)-1]),driver)\n",
    "\n",
    "            additional_facts = additional_facts.append(tmp_additional_facts, ignore_index=True)\n",
    "\n",
    "        df = pd.DataFrame(list(zip(publish_date,prices,currency,city,city_area,city_subarea,city_street,property_type,property_size,property_norooms,desc, link_to_property)), \n",
    "               columns =['Publish_Date', 'Price','Currency','City','City_Area','City_Subarea','Street','Property_Type','Property_Size_sqmtr','No_of_Rooms','Desc','Link_to_Property'])\n",
    "        df['Ad_Type'] = ad_type\n",
    "    else:\n",
    "        df = pd.DataFrame(list(zip(publish_date,prices,currency,city,city_area,city_subarea,city_street,property_type,property_size,property_norooms,desc, link_to_property)), \n",
    "               columns =['Publish_Date', 'Price','Currency','City','City_Area','City_Subarea','Street','Property_Type','Property_Size_sqmtr','No_of_Rooms','Desc','Link_to_Property'])\n",
    "        df['Ad_Type'] = None\n",
    "\n",
    "    return pd.concat([df, additional_facts], axis=1,sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_pages = 1478\n",
    "\n",
    "for page in range(1,num_pages):\n",
    "    driver = Chrome('chromedriver1.exe')\n",
    "    print('page: ' + str(page))\n",
    "    tmp_df = scrape_data('https://www.halooglasi.com', '/nekretnine/prodaja-stanova?page=', page, 'Premium',driver)\n",
    "    print(len(tmp_df))\n",
    "    df = pd.concat([df, tmp_df], axis=0, ignore_index=True,sort=True)\n",
    "    tmp_df = scrape_data('https://www.halooglasi.com', '/nekretnine/prodaja-stanova?page=', page, 'Top',driver)\n",
    "    print(len(tmp_df))\n",
    "    df = pd.concat([df, tmp_df], axis=0, ignore_index=True,sort=True)\n",
    "    tmp_df = scrape_data('https://www.halooglasi.com', '/nekretnine/prodaja-stanova?page=', page, 'Standard',driver)\n",
    "    print(len(tmp_df))\n",
    "    df = pd.concat([df, tmp_df], axis=0, ignore_index=True,sort=True)\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates().to_csv('halooglasi_data_20191106.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ad_Type</th>\n",
       "      <th>City</th>\n",
       "      <th>City_Area</th>\n",
       "      <th>City_Subarea</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Currency</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Flag_24</th>\n",
       "      <th>Flag_26</th>\n",
       "      <th>Flag_27</th>\n",
       "      <th>...</th>\n",
       "      <th>Number_of_Busses</th>\n",
       "      <th>Number_of_Trams</th>\n",
       "      <th>Number_of_Trolleys</th>\n",
       "      <th>Object_Type</th>\n",
       "      <th>Posted_By</th>\n",
       "      <th>Price</th>\n",
       "      <th>Property_Size_sqmtr</th>\n",
       "      <th>Property_Type</th>\n",
       "      <th>Publish_Date</th>\n",
       "      <th>Street</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Beograd</td>\n",
       "      <td>Opština Vračar</td>\n",
       "      <td>Krunska</td>\n",
       "      <td>Lux</td>\n",
       "      <td>€</td>\n",
       "      <td>AGENCIJSKA PROVIZIJA 2% OPIS NEKRETNINE: Uknji...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Agencija</td>\n",
       "      <td>300000</td>\n",
       "      <td>108</td>\n",
       "      <td>Stan</td>\n",
       "      <td>06.11.2019</td>\n",
       "      <td>Kneginje Zorke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Beograd</td>\n",
       "      <td>Opština Zvezdara</td>\n",
       "      <td>Kluz</td>\n",
       "      <td>Izvorno stanje</td>\n",
       "      <td>€</td>\n",
       "      <td>Dvoiposoban stan neto površine 65,00 m2 po cen...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Novogradnja</td>\n",
       "      <td>Investitor</td>\n",
       "      <td>103409</td>\n",
       "      <td>65</td>\n",
       "      <td>Stan</td>\n",
       "      <td>06.11.2019</td>\n",
       "      <td>Živka Davidovića 81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Beograd</td>\n",
       "      <td>Opština Vračar</td>\n",
       "      <td>Hram svetog Save</td>\n",
       "      <td>NaN</td>\n",
       "      <td>€</td>\n",
       "      <td>HITNA PRODAJA! Hram, Patrijarha Varnave, 4.0, ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Novogradnja</td>\n",
       "      <td>Agencija</td>\n",
       "      <td>400000</td>\n",
       "      <td>185</td>\n",
       "      <td>Stan</td>\n",
       "      <td>06.11.2019</td>\n",
       "      <td>Patrijarha Varnave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Beograd</td>\n",
       "      <td>Opština Savski venac</td>\n",
       "      <td>Beograd na vodi</td>\n",
       "      <td>Lux</td>\n",
       "      <td>€</td>\n",
       "      <td>Ekskluzivan, DELUXE stan, BEOGRAD NA VODI - zg...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Novogradnja</td>\n",
       "      <td>Agencija</td>\n",
       "      <td>270000</td>\n",
       "      <td>80</td>\n",
       "      <td>Stan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Beograd</td>\n",
       "      <td>Opština Zemun</td>\n",
       "      <td>Donji grad</td>\n",
       "      <td>Izvorno stanje</td>\n",
       "      <td>€</td>\n",
       "      <td>Stan se nalazi u lameli 8 u IV fazi izgradnje ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Novogradnja</td>\n",
       "      <td>Investitor</td>\n",
       "      <td>267600</td>\n",
       "      <td>127,44</td>\n",
       "      <td>Stan</td>\n",
       "      <td>06.11.2019</td>\n",
       "      <td>Petra Kočića</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ad_Type     City             City_Area      City_Subarea       Condition  \\\n",
       "0  Premium  Beograd        Opština Vračar           Krunska             Lux   \n",
       "1  Premium  Beograd      Opština Zvezdara              Kluz  Izvorno stanje   \n",
       "2  Premium  Beograd        Opština Vračar  Hram svetog Save             NaN   \n",
       "3  Premium  Beograd  Opština Savski venac   Beograd na vodi             Lux   \n",
       "4  Premium  Beograd         Opština Zemun        Donji grad  Izvorno stanje   \n",
       "\n",
       "  Currency                                               Desc  Flag_24  \\\n",
       "0        €  AGENCIJSKA PROVIZIJA 2% OPIS NEKRETNINE: Uknji...       -1   \n",
       "1        €  Dvoiposoban stan neto površine 65,00 m2 po cen...       -1   \n",
       "2        €  HITNA PRODAJA! Hram, Patrijarha Varnave, 4.0, ...       -1   \n",
       "3        €  Ekskluzivan, DELUXE stan, BEOGRAD NA VODI - zg...       -1   \n",
       "4        €  Stan se nalazi u lameli 8 u IV fazi izgradnje ...       -1   \n",
       "\n",
       "   Flag_26  Flag_27  ...  Number_of_Busses  Number_of_Trams  \\\n",
       "0       -1       -1  ...                 3                0   \n",
       "1        1       -1  ...                 0                0   \n",
       "2       -1       -1  ...                 0                0   \n",
       "3       -1       -1  ...                 0                0   \n",
       "4       -1       -1  ...                 0                0   \n",
       "\n",
       "   Number_of_Trolleys  Object_Type   Posted_By   Price  Property_Size_sqmtr  \\\n",
       "0                   4          NaN    Agencija  300000                  108   \n",
       "1                   0  Novogradnja  Investitor  103409                   65   \n",
       "2                   0  Novogradnja    Agencija  400000                  185   \n",
       "3                   0  Novogradnja    Agencija  270000                   80   \n",
       "4                   0  Novogradnja  Investitor  267600               127,44   \n",
       "\n",
       "   Property_Type  Publish_Date               Street  \n",
       "0           Stan    06.11.2019       Kneginje Zorke  \n",
       "1           Stan    06.11.2019  Živka Davidovića 81  \n",
       "2           Stan    06.11.2019   Patrijarha Varnave  \n",
       "3           Stan           NaN                Vista  \n",
       "4           Stan    06.11.2019         Petra Kočića  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('halooglasi_data_20191106.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "last_date = pd.to_datetime(a['Publish_Date'].dropna(),format='%d.%m.%Y').max()\n",
    "last_date_str = last_date.strftime('%d') + '.' + last_date.strftime('%m') + '.' + last_date.strftime('%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page: 45\n",
      "page: 46\n",
      "page: 47\n",
      "page: 48\n",
      "page: 49\n",
      "page: 50\n",
      "page: 51\n",
      "page: 52\n",
      "page: 53\n",
      "page: 54\n"
     ]
    }
   ],
   "source": [
    "### update with new data\n",
    "num_pages = 1500\n",
    "\n",
    "for page in range(1,num_pages):\n",
    "    driver = Chrome('chromedriver1.exe')\n",
    "    print('page: ' + str(page))\n",
    "    tmp_df = scrape_data('https://www.halooglasi.com', '/nekretnine/prodaja-stanova?page=', page, 'Premium',driver)\n",
    "    try:\n",
    "        if tmp_df.iloc[0]['Publish_Date'] == last_date_str:\n",
    "            break\n",
    "    except:\n",
    "        pass\n",
    "    df = pd.concat([df, tmp_df], axis=0, ignore_index=True,sort=True)\n",
    "    \n",
    "    tmp_df = scrape_data('https://www.halooglasi.com', '/nekretnine/prodaja-stanova?page=', page, 'Top',driver)\n",
    "    try:\n",
    "        if tmp_df.iloc[0]['Publish_Date'] == last_date_str:\n",
    "            break\n",
    "    except:\n",
    "        pass\n",
    "    df = pd.concat([df, tmp_df], axis=0, ignore_index=True,sort=True)\n",
    "    \n",
    "    tmp_df = scrape_data('https://www.halooglasi.com', '/nekretnine/prodaja-stanova?page=', page, 'Standard',driver)\n",
    "    try:\n",
    "        if tmp_df.iloc[0]['Publish_Date'] == last_date_str:\n",
    "            driver.close()\n",
    "            break\n",
    "    except:\n",
    "        pass\n",
    "    df = pd.concat([df, tmp_df], axis=0, ignore_index=True,sort=True)\n",
    "    \n",
    "    driver.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"Flag_24\": \"Flag_Roomy\", \n",
    "                   \"Flag_26\": \"Flag_Penthouse\", \n",
    "                   \"Flag_27\": \"Flag_Exchange_OK\",\n",
    "                   \"Flag_28\":\"Flag_Under_Mortgage\",\n",
    "                  \"Flag_30\":\"Flag_Rooftop\",\n",
    "                  \"Flag_32\":\"Flag_FrenchBalcony\",\n",
    "                  \"Flag_37\":\"Flag_HotWater\",\n",
    "                  \"Flag_43\":\"Flag_Fireplace\"}).drop_duplicates().to_csv('halooglasi_data_20191117.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
